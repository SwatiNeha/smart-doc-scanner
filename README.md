# ğŸ“‘ Smart Doc Scanner (Invoice/Receipt Extractor)

An end-to-end **Smart Invoice Extractor** powered by **OCR (Tesseract)** and **local LLMs (Ollama)**.  
Process single or multiple images, extract key fields (invoice number, dates, totals, tax, etc.), and use it via a friendly **Streamlit UI**, a production-ready **FastAPI** backend, or a single **Docker** image that runs both.

---

## âœ¨ Why use this?

- **Save time:** Stop typing numbers from receipts/invoices.
- **Reduce errors:** OCR + LLM > manual entry.
- **Private & affordable:** Runs with **local** models via Ollamaâ€”no cloud keys or per-call fees.
- **Flexible:** UI for humans, API for apps, batch for accountants.
- **Portable:** Dockerized for â€œworks everywhereâ€ deployment.
---

## âœ¨ Features

- ğŸ–¼ï¸ **Reads images & PDFs** (PNG, JPG/JPEG, WEBP, TIFF, BMP, PDF) using **Tesseract OCR**  
- ğŸ¤– **Extracts fields** with a **local LLM** (via [Ollama](https://ollama.com/)):
  - `invoice_number, invoice_date, due_date, subtotal, tax_rate, tax_amount, total, balance_due, cash, change, gst_id`
- âš¡ **Single-file** or **multi-file (batch)** processing  
- ğŸ’» **Two modes:**
  - **Streamlit** â†’ drag & drop UI for humans  
  - **FastAPI** â†’ machine API endpoints  
- ğŸ“¦ **Dockerized** â†’ runs anywhere with a single command  

---

## ğŸ§­ Who Is It For?

- ğŸ“Š **Accountants & operations teams** drowning in invoices  
- ğŸ‘©â€ğŸ’» **Developers** who want a private, local extractor (no API costs)  
- ğŸ“ **Students & data enthusiasts** looking to learn OCR + LLM integration  
- âš™ï¸ **Data teams** experimenting with OCR pipelines  

If youâ€™ve ever thought *â€œI wish I didnâ€™t have to type numbers from receipts againâ€* then this tool is for you.

---

## ğŸ“¸ Screenshots & Diagrams

### 1. Streamlit Batch Processing
<p align="center">
  <img src="docs/streamlit_batch_screenshot.png" alt="Streamlit batch screenshot" width="750">
</p>

### 2. Single vs Batch Invoice Pipeline
<p align="center">
  <img src="docs/single_vs_batch.png" alt="Single vs Batch pipelines" width="300">
</p>

### 3. Overall Architecture
<p align="center">
  <img src="docs/architecture.png" alt="System Architecture" width="700">
</p>

**Processing flow per invoice:**

1. Upload invoice (image/pdf)  
2. Preprocess (resize, binarize)  
3. OCR (Tesseract) â†’ extract text  
4. Focus filter â†’ keep invoice-relevant lines  
5. LLM (Ollama) â†’ extract structured fields  
6. JSON output  

---

## ğŸ“‚ Repo Structure

```
â”œâ”€â”€ app_streamlit.py # Streamlit UI
â”œâ”€â”€ fastapi_app.py # FastAPI backend
â”œâ”€â”€ batch_ocr.py # Batch processing helpers
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ Dockerfile # Single container (Streamlit + FastAPI)
â”œâ”€â”€ start.sh # Entrypoint script
â”œâ”€â”€ samples/ # Example invoices
â”œâ”€â”€ docs/ # Screenshots & diagrams
â”‚ â”œâ”€â”€ single_vs_batch.png
â”‚ â”œâ”€â”€ streamlit_batch_screenshot.png
â”‚ â””â”€â”€ architecture.png
```
---

## ğŸ”§ Setup

### Prerequisites
- **Python 3.11+** (if running locally)  
- **Tesseract OCR**  
  - Linux: `sudo apt-get install tesseract-ocr`  
  - Windows: [UB Mannheim builds](https://github.com/UB-Mannheim/tesseract/wiki)  
- **Ollama** (local LLM runtime) â†’ [Install here](https://ollama.com/)  
  - Example models:
    ```bash
    ollama pull mistral:7b
    ollama pull gemma3:latest
    ```

---

## â–¶ï¸ Usage

### A. Run Streamlit (UI only)

```bash
  pip install -r requirements.txt
  export OLLAMA_BASE="http://localhost:11434/v1"
  export LLM_MODEL="gemma3:latest"

  streamlit run app_streamlit.py
```
Open: http://localhost:8501

### B. Run FastAPI (API only)

```bash
pip install -r requirements.txt

# Point to your local Ollama server and model
export OLLAMA_BASE="http://localhost:11434/v1"
export LLM_MODEL="gemma:latest"

uvicorn fastapi_app:app --host 0.0.0.0 --port 8001 --reload
```
#### ğŸ“Œ API Docs
Interactive API documentation is available at:  
ğŸ‘‰ http://127.0.0.1:8001/docs

---

#### ğŸ“Œ Endpoints

##### Health Check
GET /health

##### OCR Only
POST /ocr

##### Extract (Single File)
POST /extract

##### Extract Batch (Multiple Files)
POST /extract-batch

---

#### ğŸ–¥ï¸ Example Usage (cURL)

##### Single File
```bash
curl -X POST "http://127.0.0.1:8001/extract" \
  -F "file=@samples/invoice1.jpg"
```
##### Multiple Files
```bash
curl -X POST "http://127.0.0.1:8001/extract-batch" \
  -F "files=@samples/invoice1.jpg" \
  -F "files=@samples/invoice2.png"
```
### C. Docker (UI + API Together)

#### Build
```bash
docker build -t smart-doc-scanner .
```

### Run
```bash
docker run --rm -p 8001:8001 -p 8501:8501 \
  --add-host=host.docker.internal:host-gateway \
  -e OLLAMA_BASE=http://host.docker.internal:11434/v1 \
  -e LLM_MODEL=gemma3:latest \
  smart-doc-scanner
```

#### Access
- API Docs â†’ http://127.0.0.1:8001/docs  
- UI â†’ http://127.0.0.1:8501  

> **Note (Windows/macOS + Docker):**  
> Use `host.docker.internal` so the container can reach your hostâ€™s Ollama running at `http://localhost:11434`.

---

#### ğŸ§ª Example Output
```json
{
  "filename": "invoice1.jpg",
  "fields": {
    "invoice_number": "2022435",
    "invoice_date": "2022-07-19",
    "due_date": "2022-08-03",
    "subtotal": "2100.00",
    "tax_rate": "10%",
    "tax_amount": "210.00",
    "total": "2510.00",
    "balance_due": "NOT FOUND",
    "cash": "NOT FOUND",
    "change": "NOT FOUND",
    "gst_id": "NOT FOUND"
  },
  "model": "gemma3:latest"
}
```

## ğŸ› ï¸ Troubleshooting

**â€œLLM read timeout / connect errorâ€**  
- Make sure **Ollama** is running and the model is pulled.  
- Check `OLLAMA_BASE` (default `http://localhost:11434/v1`).  
- On Docker, use `http://host.docker.internal:11434/v1`.

**â€œOCR result is empty / poor textâ€**  
- Low-res or skewed scans harm OCR; try higher quality or better lighting.  
- Consider deskewing/denoising pre-processing if needed.

**Windows Tesseract path**  
- Set `TESSERACT_CMD` env var if Tesseract isnâ€™t on PATH. Example:  
  ```bash
  TESSERACT_CMD="C:\Program Files\Tesseract-OCR\tesseract.exe"
  ```

  ## âš ï¸ Known Limitations

- â³ **Speed**: CPU-bound; batch can be slow. GPU acceleration is a future upgrade.  
- ğŸ“¸ **OCR Quality**: Blurry/low-contrast images reduce accuracy.  
- ğŸ§© **LLM Quirks**: May hallucinate fields; strict JSON schema helps contain it.  
- ğŸŒ **Languages**: English by default; add Tesseract language packs for more.  

---

## ğŸš€ Roadmap

- âš¡ GPU acceleration (CUDA/DirectML) for faster extraction  
- ğŸŒ Multi-language OCR (Spanish, German, Hindi, etc.)  
- ğŸ‘€ Vision-Language models â†’ skip OCR step entirely  
- ğŸ”— Accounting integrations (Xero, QuickBooks, Notion)  
- â˜ï¸ Hosted/Public API for easy third-party integrations  

---

## ğŸ™Œ Credits

- **OCR** â†’ [Tesseract](https://github.com/tesseract-ocr/tesseract)  
- **LLM runtime** â†’ [Ollama](https://ollama.com/)  
- **Backend** â†’ [FastAPI](https://fastapi.tiangolo.com/)  
- **Frontend** â†’ [Streamlit](https://streamlit.io/)  
- **Packaging** â†’ [Docker](https://www.docker.com/) 
